# AI-102 Hands-On Labs

This page catalogs hands-on labs built from practice exam questions. Each lab uses Terraform or Azure Bicep to create dedicated environments for testing specific AI-102 concepts.

---

## ðŸ“ˆ Lab Statistics

- **Total Labs**: 3
- **Generative AI**: 1
- **Agentic**: 0
- **Computer Vision**: 0
- **Natural Language Processing**: 0
- **Knowledge Mining**: 1
- **AI Services**: 1

---

## ðŸ§ª Labs

### Generative AI

- **[DALL-E Image Generation with Azure OpenAI](generative-ai/lab-dalle-image-gen/README.md)** - Test DALL-E 3 image generation capabilities, model parameters, and Azure AI Foundry portal features

### Knowledge Mining

- **[Azure AI Search â€” Improve Query Performance with Partitions](knowledge-mining/lab-search-query-perf/README.md)** - Deploy Azure AI Search with multiple partitions to optimize query performance and understand the difference between partitions and replicas

### AI Services

- **[Azure AI Content Safety - Text and Image Moderation](ai-services/lab-content-safety/README.md)** - Deploy Azure AI Content Safety and test text and image moderation in Content Safety Studio and via the REST API

---

## ðŸ“‹ Governance & Standards

All labs in this repository are built following the comprehensive governance policy documented in [GOVERNANCE.md](../../GOVERNANCE.md). This ensures:

- **Consistent naming conventions** for resource groups and resources
- **Standardized tagging** across all deployments for tracking and cleanup
- **Cost management practices** including resource limits and auto-shutdown policies
- **Code quality standards** with proper header comments and structured code
- **Best practices** for infrastructure-as-code patterns in Terraform and Bicep

---
