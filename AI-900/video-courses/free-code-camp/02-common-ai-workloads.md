# Common AI Workloads

**Channel:** freeCodeCamp.org
**Duration:** 11:16:25
**URL:** https://www.youtube.com/watch?v=10PbGbTUSAg

---

## Anomaly Detection AI

**Timestamp**: 00:34:06 ‚Äì 00:34:59

**Key Concepts**  
- Anomaly detection is the process of identifying outliers or abnormal data points that deviate from the norm.  
- Anomalies can indicate suspicious or malicious activity in data or access patterns.  
- Manual anomaly detection is tedious; machine learning improves efficiency and accuracy.  
- Azure provides an Anomaly Detector service to automatically detect anomalies and help troubleshoot issues quickly.

**Definitions**  
- **Anomaly**: An abnormal data point or event marked by deviation from the norm or standard.  
- **Anomaly Detection**: The process of finding outliers or anomalies within a dataset.

**Key Facts**  
- Use cases for anomaly detection include:  
  - Data cleaning  
  - Intrusion detection  
  - Fraud detection  
  - System health monitoring  
  - Event detection  
  - Sensor networks and ecosystem disturbance detection  
  - Detection of critical and cascading flaws  
- Azure‚Äôs Anomaly Detector is a machine learning service designed to detect anomalies in data efficiently.

**Examples**  
- None specifically detailed in this segment, but use cases imply examples such as detecting fraud or system faults.

**Key Takeaways üéØ**  
- Understand what constitutes an anomaly and why detecting it is important.  
- Remember the broad range of practical applications for anomaly detection.  
- Know that ML-based anomaly detection is more efficient than manual methods.  
- Be aware of Azure‚Äôs Anomaly Detector as a key cloud service for anomaly detection tasks.

---

## Computer Vision AI

**Timestamp**: 00:34:59 ‚Äì 00:37:05  

**Key Concepts**  
- Computer vision uses machine learning neural networks to understand digital images and videos at a high level.  
- Deep learning algorithms for computer vision include convolutional neural networks (CNNs) and recurrent neural networks (RNNs).  
- Types of computer vision tasks: image classification, object detection, semantic segmentation, image analysis, optical character recognition (OCR), and facial detection.  
- Azure offers several computer vision-related services to analyze images/videos, build custom models, detect faces/emotions, and extract data from documents.  

**Definitions**  
- **Computer Vision**: The use of machine learning neural networks to gain high-level understanding of digital images or videos.  
- **Convolutional Neural Networks (CNNs)**: Deep learning algorithms inspired by the human eye‚Äôs processing, primarily used for image and video recognition.  
- **Recurrent Neural Networks (RNNs)**: Neural networks commonly used for handwriting and speech recognition, with other applications as well.  
- **Image Classification**: Categorizing an image or video into a predefined class or category.  
- **Object Detection**: Identifying and labeling objects within an image or video along with their location boundaries.  
- **Semantic Segmentation**: Drawing pixel-level masks around objects or segments in an image, useful for detecting objects and movement.  
- **Image Analysis**: Applying descriptive context labels to images or videos (e.g., identifying an employee sitting at a desk in Tokyo).  
- **Optical Character Recognition (OCR)**: Extracting text from images or videos into editable digital text.  
- **Facial Detection**: Detecting faces in images or videos, drawing location boundaries, and labeling expressions.  

**Key Facts**  
- CNNs are inspired by the human eye‚Äôs information processing.  
- RNNs are typically used for handwriting and speech recognition.  
- Microsoft‚Äôs Seeing AI app (iOS only) uses computer vision to audibly describe people and objects for visually impaired users.  
- Azure Computer Vision Service offerings include:  
  - **Computer Vision**: Analyze images/videos, extract descriptions, tags, objects, and text.  
  - **Custom Vision**: Build custom image classification and object detection models using your own images.  
  - **Face**: Detect and identify people and emotions in images.  
  - **Form Recognizer**: Scan documents and convert them into editable key-value or tabular data.  

**Examples**  
- Seeing AI app: Uses device camera to identify people and objects and audibly describe them for visually impaired users (iOS only).  
- Image analysis example: Describing a scene such as ‚Äúan employee sitting at a desk in Tokyo.‚Äù  

**Key Takeaways üéØ**  
- Understand the main types of computer vision tasks and their purposes (classification, detection, segmentation, OCR, facial detection).  
- Remember CNNs are the primary deep learning model for image/video recognition; RNNs are more for sequential data like handwriting and speech.  
- Be familiar with Azure‚Äôs computer vision services and their specific capabilities (Computer Vision, Custom Vision, Face, Form Recognizer).  
- Seeing AI is a practical Microsoft app example demonstrating computer vision‚Äôs accessibility use case.  
- OCR is important for converting image-based text into editable digital formats‚Äîcommonly tested in exams.  
- Semantic segmentation involves pixel-level object identification, which is more detailed than object detection.

---

## Natural Language Processing AI

**Timestamp**: 00:37:05 ‚Äì 00:38:42

**Key Concepts**  
- Natural Language Processing (NLP) enables machines to understand and interpret human language contextually.  
- NLP applies to analyzing text in documents and emails, as well as interpreting spoken language.  
- Sentiment analysis determines customer emotions (e.g., happy or sad).  
- Speech synthesis allows voice assistants to talk to users.  
- Automatic translation of spoken or written language between languages.  
- Interpretation of spoken or written commands to trigger appropriate actions.  
- Text analytics services include sentiment analysis, key phrase extraction, language detection, and named entity recognition.  
- Real-time text translation and multi-language support are available via translator services.  
- Speech services transcribe audible speech into searchable text.  
- Language Understanding Intelligent Service (LUIS) is an NLP service for understanding human language in apps, websites, chatbots, IoT devices, etc.  

**Definitions**  
- **Natural Language Processing (NLP)**: Machine learning technology that understands the context of a body of related text (corpus) and interprets text and speech.  
- **Corpus**: A body of related text used for NLP analysis.  
- **Sentiment Analysis**: Technique to determine the emotional tone behind a body of text.  
- **Key Phrase Extraction**: Identifying important phrases relevant to the topic within text.  
- **Named Entity Recognition**: Detecting and categorizing entities (like names, places) in text.  
- **LUIS (Language Understanding Intelligent Service)**: An NLP service that enables applications to understand human language inputs.  

**Key Facts**  
- Microsoft‚Äôs Cortana is a well-known voice assistant example using NLP and Bing search integration.  
- Azure‚Äôs machine learning platform offers text analytics capabilities such as sentiment analysis, key phrase extraction, language detection, and entity recognition.  
- Translator service supports real-time text translation and multiple languages.  
- Speech service converts spoken language into readable, searchable text.  

**Examples**  
- Customer sentiment analysis to gauge if customers are happy or sad.  
- Cortana performing tasks like setting reminders and answering questions using Bing search.  
- Using LUIS to enable chatbots, websites, or IoT devices to understand human language.  

**Key Takeaways üéØ**  
- Understand that NLP is about machines interpreting and contextualizing human language, both written and spoken.  
- Remember key Azure NLP services: Text Analytics, Translator, Speech Service, and LUIS.  
- Know practical NLP applications: sentiment analysis, speech synthesis, translation, command interpretation.  
- Cortana is a prime example of NLP in action within Microsoft‚Äôs ecosystem.  
- LUIS is critical for building conversational AI that understands user intent.  
- Exam questions may focus on differentiating NLP capabilities and identifying appropriate Azure services for language tasks.

---

## Conversational AI

**Timestamp**: 00:38:42 ‚Äì 00:40:16

**Key Concepts**  
- Conversational AI enables technology to participate in human-like conversations.  
- It commonly uses Natural Language Processing (NLP) to understand and respond to human language.  
- Conversational AI includes chatbots, voice assistants, and interactive voice recognition systems.  
- Interactive voice recognition systems differ from traditional interactive voice response (IVR) systems by understanding spoken language rather than just keypad inputs.  
- Use cases span customer support, accessibility, HR processes, healthcare, IoT devices, and computer software.  
- Azure provides two main services for conversational AI: Q&A Maker and Azure Bot Service.

**Definitions**  
- **Conversational AI**: Technology that can engage in conversations with humans, often leveraging NLP.  
- **Interactive Voice Recognition System**: A system that can interpret and act on human speech, unlike traditional IVR systems that rely on keypad inputs.  
- **Q&A Maker**: An Azure service to create conversational question-and-answer bots from existing content (knowledge bases).  
- **Azure Bot Service**: An intelligent, serverless bot service that scales on demand for creating, publishing, and managing bots.

**Key Facts**  
- Conversational AI typically uses NLP (e.g., LUIS in Azure).  
- Interactive voice recognition systems represent an evolution from IVR systems by processing spoken language.  
- Azure Q&A Maker builds bots from existing content, facilitating quick deployment of FAQ bots.  
- Azure Bot Service supports scalable, serverless bot deployment and management.

**Examples**  
- Chatbots for online customer support answering FAQs like shipping questions.  
- Voice-operated user interfaces for accessibility, especially for visually impaired users.  
- HR applications such as employee training, onboarding, and updating employee info (not commonly seen but noted).  
- Healthcare claim processing (hypothetical example, more relevant in privatized healthcare systems).  
- IoT devices like Amazon Alexa, Apple Siri, Google Home.  
- Computer software autocomplete features (e.g., Cortana).

**Key Takeaways üéØ**  
- Understand the difference between IVR and interactive voice recognition systems.  
- Remember the main Azure services for conversational AI: Q&A Maker (knowledge base bots) and Azure Bot Service (bot lifecycle management).  
- Recognize the broad applicability of conversational AI across industries and devices.  
- Conversational AI relies heavily on NLP technologies to interpret and respond to human language.
