# Capabilities of Azure OpenAI Service

**Channel:** freeCodeCamp.org
**Duration:** 11:16:25
**URL:** https://www.youtube.com/watch?v=10PbGbTUSAg

---

## Introduction to Azure OpenAI Service

**Timestamp**: 02:08:01 ‚Äì 02:10:29

**Key Concepts**  
- Azure OpenAI Service is a cloud-based platform for deploying and managing OpenAI‚Äôs advanced language models.  
- Combines OpenAI‚Äôs latest language models with Azure‚Äôs security and scalability.  
- Supports multiple model types tailored for different tasks: GPT-4, GPT-3.5, GPT-3.5 Turbo, embedding models, DALL-E, Whisper.  
- Core concepts include prompts and completions, tokens, resources, deployments, prompt engineering, and model selection.  
- Users interact with the service via prompts (text commands) and receive completions (model-generated responses).  
- Tokens are units of text (words or chunks) used to process requests; token count impacts latency and throughput.  
- Deployments require creating resources in an Azure subscription and selecting specific models via deployment APIs.  
- Prompt engineering is critical for guiding model output and requires skillful prompt construction.  
- Azure OpenAI Studio is a web-based environment for deploying, testing, and managing models, supporting generative AI app development.  
- Access to Azure OpenAI Service is currently limited due to high demand and responsible AI commitments, prioritizing existing Microsoft partners and low-risk use cases.

**Definitions**  
- **Azure OpenAI Service**: A cloud platform integrating OpenAI‚Äôs language models with Azure‚Äôs infrastructure for secure, scalable AI deployments.  
- **Prompt**: A text input provided by the user to the model to generate a response.  
- **Completion**: The text output generated by the model in response to a prompt.  
- **Token**: A unit of text (word or character chunk) used internally by the model to process language.  
- **Deployment**: The process of setting up a specific model instance within Azure OpenAI Service to handle requests.  
- **Prompt Engineering**: The practice of designing and refining prompts to elicit desired responses from AI models.  
- **Azure OpenAI Studio**: A web-based interface for managing, deploying, and testing OpenAI models on Azure.

**Key Facts**  
- GPT-4 and GPT-3.5 models generate text and code from natural language prompts.  
- GPT-3.5 Turbo is optimized for conversational AI and chat applications.  
- Embedding models convert text into numeric sequences for similarity analysis.  
- DALL-E models generate images from textual descriptions and are currently in testing within Azure OpenAI Studio.  
- Token costs vary by task; image generation token cost depends on image size and detail level.  
- Users must create an Azure resource and deploy models via APIs to use the service.  
- Access is restricted and prioritized for partners with low-risk use cases and responsible AI safeguards.

**Examples**  
- Prompt example: Asking the model to count to 5 in a loop results in generated code that performs the task.  
- DALL-E models generate images from word descriptions without manual setup.

**Key Takeaways üéØ**  
- Understand the different model types and their primary use cases (text/code generation, conversation, embeddings, image generation).  
- Know the importance of tokens and how they affect performance and cost.  
- Be familiar with the deployment process: creating Azure resources and deploying models via APIs.  
- Recognize the critical role of prompt engineering in influencing model outputs.  
- Remember that Azure OpenAI Studio is the main interface for working with these models on Azure.  
- Be aware of current access limitations and Microsoft‚Äôs responsible AI approach when using Azure OpenAI Service.

---

## Azure OpenAI Studio

**Timestamp**: 02:10:29 ‚Äì 02:11:44

**Key Concepts**  
- Azure OpenAI Studio is a web-based environment for developers and AI professionals.  
- It enables deployment, testing, and management of large language models (LLMs) on Azure.  
- Supports generative AI app development through interactive tools like the Chat Playground.  
- Access to Azure OpenAI Studio is currently limited due to high demand and responsible AI considerations.  
- Collaborations prioritize existing Microsoft partners, low-risk use cases, and inclusion of safeguards.  
- The Chat Playground interface allows users to input queries, test AI responses, and adjust parameters to fine-tune behavior.  

**Definitions**  
- **Azure OpenAI Studio**: A web-based platform for deploying, testing, and managing Azure OpenAI large language models, facilitating generative AI application development.  
- **Chat Playground**: An interactive interface within Azure OpenAI Studio where users can test AI chatbots by typing messages and receiving responses, with adjustable parameters to control AI behavior.  

**Key Facts**  
- The Chat Playground interface includes:  
  - A central chat area for user input and AI replies.  
  - A left-side menu for navigation and assistant setup (with reminders to save changes).  
  - A right-side panel with adjustable parameters controlling response length, randomness, and repetition.  
- Access is limited and prioritized for partners engaged in lower-risk AI use cases with safeguards.  

**Examples**  
- Using the Chat Playground to provide few-shot examples and test large language models interactively.  

**Key Takeaways üéØ**  
- Understand that Azure OpenAI Studio is the primary environment for working with Azure OpenAI models in a controlled, web-based setting.  
- Remember the Chat Playground as a key tool for testing and fine-tuning AI chatbot responses.  
- Be aware of current access restrictions and the focus on responsible AI use and partnerships.  
- Know the interface layout: chat area (center), navigation and setup (left), and response parameter controls (right).  
- Recognize the importance of saving changes when configuring the assistant.

---

## Azure OpenAI service pricing

**Timestamp**: 02:11:44 ‚Äì 02:13:14

**Key Concepts**  
- Azure OpenAI Service pricing is primarily pay-per-use based.  
- Pricing varies depending on the model type, context size, and usage (prompt vs completion tokens).  
- Higher quality and larger context models cost more.  
- Pricing can be per 1,000 tokens or per hour depending on the model and usage.  

**Definitions**  
- **Prompt tokens**: Tokens sent as input to the model.  
- **Completion tokens**: Tokens generated by the model as output.  
- **Context size**: The maximum number of tokens the model can consider at once (e.g., 4K, 8K, 16K, 32K, 128K tokens).  

**Key Facts**  
- GPT-3.5 Turbo (4K context):  
  - $0.0015 per 1,000 prompt tokens  
  - $0.002 per 1,000 completion tokens  
- GPT-3.5 Turbo (16K context):  
  - $0.003 per 1,000 prompt tokens  
  - $0.004 per 1,000 completion tokens  
- GPT-3.5 Turbo1106 (16K context): Pricing not available  
- GPT-4 (8K context):  
  - $0.03 per 1,000 prompt tokens  
  - $0.06 per 1,000 completion tokens  
- GPT-4 (32K context):  
  - $0.06 per 1,000 prompt tokens  
  - $0.12 per 1,000 completion tokens  
- GPT-4 Turbo and GPT-4 Turbo Vision (128K context): Pricing not listed  
- Other models (base, fine-tuning, image, embedding, speech) also use pay-per-use pricing but details were not specified.  

**Examples**  
- None specifically mentioned beyond pricing examples for GPT models.  

**Key Takeaways üéØ**  
- Remember that prompt and completion tokens are priced separately.  
- Larger context windows increase pricing due to higher resource usage.  
- GPT-4 models are significantly more expensive than GPT-3.5 Turbo models.  
- Pricing details for some newer or specialized models (e.g., GPT-4 Turbo Vision) may not be publicly available.  
- Understand the pay-per-use model as a core pricing approach in Azure OpenAI Service.  
- Be aware that costs can vary widely depending on the model and token usage, which is critical for budgeting and cost management in exam scenarios.

---

## What are Copilots

**Timestamp**: 02:13:14 ‚Äì 02:15:43

**Key Concepts**  
- Copilots are AI-powered computing tools integrated into applications to assist users with common tasks.  
- They use generative AI models to generate content, synthesize information, and support strategic planning.  
- Copilots follow a standard architecture enabling developers to create custom versions tailored to specific business needs.  
- Creation involves training or fine-tuning large language models, deploying them, and building prompts to generate useful outputs.  
- Copilots enhance productivity and creativity by providing AI-generated assistance within familiar software environments.

**Definitions**  
- **Copilot**: A generative AI assistant embedded in applications that helps users perform tasks by leveraging the content within those applications to generate relevant and contextual outputs.

**Key Facts**  
- Copilots can appear as chat features alongside documents or files.  
- They utilize pre-trained models from services like Azure OpenAI, which can be used as-is or fine-tuned with custom data.  
- Microsoft Copilot is integrated across Microsoft products (Word, Excel, PowerPoint, etc.) to assist with document creation, summarization, and planning.  
- Microsoft Bing includes a Copilot that provides natural language answers by understanding search context.  
- Microsoft 365 Copilot supports workflow tasks in tools like PowerPoint and Outlook.  
- GitHub Copilot aids software developers by suggesting code snippets, documenting code, and supporting testing to reduce errors.

**Examples**  
- Microsoft Copilot: Assists in creating documents, spreadsheets, presentations, and strategic planning.  
- Microsoft Bing Copilot: Enhances search by generating contextual natural language answers.  
- Microsoft 365 Copilot: Helps with emails, presentations, spreadsheets, and other productivity tasks.  
- GitHub Copilot: Provides real-time coding assistance, documentation, and testing support for developers.

**Key Takeaways üéØ**  
- Understand that Copilots are AI assistants embedded within applications to improve user productivity through generative AI.  
- Remember that Copilots leverage both pre-trained and fine-tuned large language models.  
- Be able to identify examples of Copilots in Microsoft products and their specific roles.  
- Recognize the importance of prompt engineering and deployment in making Copilots effective.  
- Focus on how Copilots transform workflows by automating first drafts, summarization, coding help, and strategic planning.

---

## Prompt engineering

**Timestamp**: 02:15:43 ‚Äì 02:18:51

**Key Concepts**  
- Prompt engineering improves interaction between humans and generative AI by refining prompts/instructions.  
- It benefits both developers building AI applications and end users interacting with them.  
- System messages set context, expectations, and constraints for AI responses.  
- Writing precise and explicit prompts maximizes AI response quality.  
- One-shot learning: AI performs tasks correctly from a single example without prior training.  
- Prompt engineering workflow involves multiple iterative steps from understanding the task to refining output.

**Definitions**  
- **Prompt engineering**: The process of refining prompts or instructions given to an AI to generate higher quality responses.  
- **System message**: A prompt component that defines the AI‚Äôs role, style, and constraints (e.g., ‚ÄúYou are a helpful assistant responding cheerfully‚Äù).  
- **One-shot learning**: AI‚Äôs ability to perform a task correctly after seeing only one example or instance.  

**Key Facts**  
- A well-structured prompt example: ‚ÄúCreate a list of 10 things to do in Edinburgh during August.‚Äù  
- Prompt engineering workflow steps:  
  1. Task understanding ‚Äì know what you want the AI to do  
  2. Crafting prompts ‚Äì write instructions for the AI  
  3. Prompt alignment ‚Äì ensure instructions match AI capabilities  
  4. Optimizing prompt ‚Äì improve instructions for better responses  
  5. AI model processing ‚Äì AI processes instructions  
  6. Generating output ‚Äì AI produces answer/result  
  7. Output refinement ‚Äì tweak AI‚Äôs answer  
  8. Iterative improvement ‚Äì continuously improve instructions and answers  

**Examples**  
- User query: ‚ÄúCan my camera handle the rainy season if I go to the Amazon rainforest next week?‚Äù  
- Prompt engineering components used: weather resistance feature check, user‚Äôs equipment database, rainforest climate data, product specs, travel tips for photographers.  
- AI integrates user question with climate data and product info to respond:  
  ‚ÄúYour current camera model, the ProShot Mark V, is weather-sealed for high humidity and rain, suitable for the Amazon rainy season. Consider a rain cover for heavy rains.‚Äù  

**Key Takeaways üéØ**  
- Always be precise and explicit in prompts to get targeted, relevant AI outputs.  
- Use system messages to control AI tone, style, and constraints.  
- Understand and align prompts with what the AI model can do.  
- Follow the prompt engineering workflow for effective AI interaction and continuous improvement.  
- One-shot learning enables AI to perform new tasks from minimal examples‚Äîleverage this in prompt design.  
- Incorporate relevant context and data sources in prompts to improve response accuracy.

---

## Grounding

**Timestamp**: 02:18:51 ‚Äì 02:20:36

**Key Concepts**  
- Grounding is a prompt engineering technique that involves providing specific, relevant context within a prompt to improve AI responses.  
- Grounding helps large language models (LLMs) produce more accurate and contextually relevant outputs.  
- It differs from general prompt engineering by focusing on enriching prompts with context rather than just crafting instructions or format.  
- Grounding ensures the AI has sufficient information to understand and process the prompt correctly.  
- Prompt engineering is broader and includes techniques like style, format, examples, and question framing.  
- Grounding supports responsible AI by helping ensure outputs are accurate and aligned with ethical standards.  
- Grounding fits within a framework of prompt engineering, fine-tuning, and training, with prompt engineering at the top (broadest), fine-tuning in the middle, and training at the base (most resource-intensive).  
- LLM operations (LLM ops) and responsible AI principles are foundational across all stages of LLM application development.

**Definitions**  
- **Grounding**: A technique in prompt engineering where relevant and specific context is included in the prompt to help the AI model generate more accurate and relevant responses.  
- **Prompt Engineering**: The broader art of designing prompts to elicit desired outputs from AI models, including format, style, and strategic use of examples or questions.

**Key Facts**  
- Grounding allows leveraging LLMs for tasks they were not explicitly trained on without retraining the model.  
- The grounding framework is visualized as a triangle with prompt engineering at the top, fine-tuning below, and training at the base, indicating increasing complexity and resource requirements.  
- Responsible AI and operational efficiency are emphasized as foundational across all LLM development stages.

**Examples**  
- To summarize an email using an LLM, include the actual email text in the prompt along with a command to summarize it. This is an example of grounding by providing relevant context.

**Key Takeaways üéØ**  
- Remember that grounding is about enriching prompts with context to improve AI understanding and output quality.  
- Grounding differs from prompt engineering, which is broader and includes other prompt design techniques.  
- Use grounding to enable LLMs to perform tasks without retraining by supplying relevant data within the prompt.  
- Understand the grounding framework‚Äôs place relative to fine-tuning and training in terms of complexity and resource use.  
- Keep responsible AI principles and operational efficiency in mind when applying grounding techniques.  
- Practical application: Always include necessary context in prompts for best results, e.g., full text when asking for summaries.

---

## Copilot demo

**Timestamp**: 02:20:36 ‚Äì 02:24:04

**Key Concepts**  
- Copilot with GPT-4 on Microsoft Bing enables interactive AI-powered assistance including text generation, coding help, and image creation.  
- Conversation styles can be adjusted: creative (imaginative), balanced (middle ground), or precise (factual).  
- Copilot integrates with DALL-E 3 for AI image generation and modification.  
- Copilot can generate and modify code in multiple programming languages such as Python and JavaScript.  
- Responses include sourced information with clickable links for verification and further reading.  
- Follow-up question suggestions are provided to deepen understanding or continue the conversation.

**Definitions**  
- **Copilot**: An AI assistant powered by GPT-4 integrated into Microsoft Bing that supports text generation, coding, and image creation.  
- **DALL-E 3**: An AI image generation service integrated with Copilot that creates and edits images based on user prompts.

**Key Facts**  
- Popular prompt examples include:  
  - Creating images (e.g., concept kitchen)  
  - Generating product ideas  
  - Explaining AI to a 6th grader  
  - Writing Python code for flavor combinations  
- Example prompt style used in demo: ‚ÄúSummarize the main differences between supervised and unsupervised learning for the AI-900 exam.‚Äù  
- Copilot provides internet-sourced answers with direct links to original sources.  
- Image generation example: ‚ÄúCreate an image of a cute dog running through a green field on a sunny day.‚Äù  
- Image modification options include adding a rainbow, changing the animal (dog to cat), or altering the sky colors.  
- Code generation examples:  
  - Python function to check if a number is prime  
  - JavaScript function to reverse a string

**Examples**  
- Summarizing supervised vs unsupervised learning:  
  - Supervised learning uses labeled data with correct outputs.  
  - Unsupervised learning uses unlabeled data to find patterns.  
- Image generation and modification:  
  - Generated a dog running in a field, then changed it to a cat.  
- Code generation:  
  - Python prime number checker function.  
  - JavaScript string reversal function.

**Key Takeaways üéØ**  
- Remember that Copilot can be used for a variety of tasks: text explanation, coding, and image generation.  
- Adjusting conversation style affects the creativity vs factual precision of responses.  
- Copilot‚Äôs integration with DALL-E 3 allows seamless image creation and editing from text prompts.  
- Generated answers come with source links‚Äîuse these for verifying information and further study.  
- Copilot supports multiple programming languages, useful for coding exam questions or practice.  
- Using follow-up suggestions can help deepen understanding or explore related topics efficiently.
